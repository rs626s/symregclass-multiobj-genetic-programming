
Running on dataset: Diabetes

Top GP Models:
Model 1:
  Expression: sub(sub(ARG4, -0.5467496134784091), sub(ARG6, add(add(sub(ARG8, ARG0), add(sub(ARG4, -0.5467496134784091), ARG9)), add(ARG4, ARG3))))
  Features used: 6
Model 2:
  Expression: neg(sub(ARG4, 0.7655054936999734))
  Features used: 1
Model 3:
  Expression: sub(ARG2, -0.5467496134784091)
  Features used: 1

Hypothesis Evaluation for Diabetes:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: MSE = 6743.9611
  Random Forest: MSE = 3476.8037
  Linear Regression: MSE = 2993.0813

Running on dataset: California

Top GP Models:
Model 1:
  Expression: mul(ARG0, neg(-0.3485823673125823))
  Features used: 1
Model 2:
  Expression: add(0.8509036698360588, ARG3)
  Features used: 1
Model 3:
  Expression: neg(ARG3)
  Features used: 1

Hypothesis Evaluation for California:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: MSE = 0.6284
  Random Forest: MSE = 0.3113
  Linear Regression: MSE = 0.5494

Running on dataset: Iris

Top GP Models:
Model 1:
  Expression: neg(ARG1)
  Features used: 1
Model 2:
  Expression: neg(ARG0)
  Features used: 1
Model 3:
  Expression: neg(ARG2)
  Features used: 1

Hypothesis Evaluation for Iris:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.9600
  Random Forest: Accuracy = 0.9667
  Logistic Regression: Accuracy = 0.9733

Running on dataset: Wine

Top GP Models:
Model 1:
  Expression: neg(ARG1)
  Features used: 1
Model 2:
  Expression: neg(ARG10)
  Features used: 1
Model 3:
  Expression: neg(ARG7)
  Features used: 1

Hypothesis Evaluation for Wine:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.8876
  Random Forest: Accuracy = 0.9776
  Logistic Regression: Accuracy = 0.9611

Running on dataset: Digits

Top GP Models:
Model 1:
  Expression: neg(ARG63)
  Features used: 1
Model 2:
  Expression: neg(ARG7)
  Features used: 1
Model 3:
  Expression: neg(ARG47)
  Features used: 1

Hypothesis Evaluation for Digits:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.7819
  Random Forest: Accuracy = 0.9382
  Logistic Regression: Accuracy = 0.9143

Running on dataset: BreastCancer

Top GP Models:
Model 1:
  Expression: neg(ARG16)
  Features used: 1
Model 2:
  Expression: neg(ARG25)
  Features used: 1
Model 3:
  Expression: neg(ARG3)
  Features used: 1

Hypothesis Evaluation for BreastCancer:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.9191
  Random Forest: Accuracy = 0.9631
  Logistic Regression: Accuracy = 0.9526
