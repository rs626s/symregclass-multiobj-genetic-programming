
Running on dataset: Diabetes

Top GP Models:
Model 1:
  Expression: neg(sub(sub(-0.98282911772935, ARG9), add(ARG5, ARG5)))
  Features used: 3
Model 2:
  Expression: add(ARG3, add(0.25894689036885277, add(ARG3, 0.25894689036885277)))
  Features used: 2
Model 3:
  Expression: neg(add(-0.31630021778575257, ARG2))
  Features used: 1

Hypothesis Evaluation for Diabetes:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: MSE = 6490.2912
  Random Forest: MSE = 3313.0366
  Linear Regression: MSE = 2993.0813

Running on dataset: California

Top GP Models:
Model 1:
  Expression: add(add(neg(ARG7), sub(ARG7, -0.9921151296833552)), ARG3)
  Features used: 3
Model 2:
  Expression: add(neg(-0.8919151323242407), ARG3)
  Features used: 1
Model 3:
  Expression: mul(ARG2, 0.30013507194313394)
  Features used: 1

Hypothesis Evaluation for California:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: MSE = 0.6377
  Random Forest: MSE = 0.3098
  Linear Regression: MSE = 0.5494

Running on dataset: Iris

Top GP Models:
Model 1:
  Expression: neg(ARG3)
  Features used: 1
Model 2:
  Expression: neg(ARG1)
  Features used: 1
Model 3:
  Expression: neg(ARG2)
  Features used: 1

Hypothesis Evaluation for Iris:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.9667
  Random Forest: Accuracy = 0.9667
  Logistic Regression: Accuracy = 0.9733

Running on dataset: Wine

Top GP Models:
Model 1:
  Expression: neg(ARG4)
  Features used: 1
Model 2:
  Expression: neg(ARG2)
  Features used: 1
Model 3:
  Expression: neg(ARG3)
  Features used: 1

Hypothesis Evaluation for Wine:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.8765
  Random Forest: Accuracy = 0.9721
  Logistic Regression: Accuracy = 0.9611

Running on dataset: Digits

Top GP Models:
Model 1:
  Expression: neg(ARG24)
  Features used: 1
Model 2:
  Expression: neg(ARG56)
  Features used: 1
Model 3:
  Expression: neg(ARG48)
  Features used: 1

Hypothesis Evaluation for Digits:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.7891
  Random Forest: Accuracy = 0.9405
  Logistic Regression: Accuracy = 0.9143

Running on dataset: BreastCancer

Top GP Models:
Model 1:
  Expression: neg(ARG20)
  Features used: 1
Model 2:
  Expression: neg(ARG1)
  Features used: 1
Model 3:
  Expression: neg(ARG16)
  Features used: 1

Hypothesis Evaluation for BreastCancer:
  Accuracy Condition: Failed
  Complexity Condition: Passed
  Hypothesis Not Supported: One or more conditions failed.

Baseline comparisons:
  Decision Tree: Accuracy = 0.9226
  Random Forest: Accuracy = 0.9614
  Logistic Regression: Accuracy = 0.9526
